{
  "checkpoint_metadata": {
    "type": "pre_resubmission",
    "timestamp": "2026-02-11T14:50:26.694833",
    "project_id": "65633"
  },
  "form_data": {
    "metadata": {
      "proposal_title": "NeuroAI: Toward a Volumetric 3D  Molecular Brain Atlas: A Multimodal  Transformer Unifying scRNA-seq, ST and H&E",
      "principal_investigator": "Jesper Nils Tegner",
      "proposal_date": "2025-12-09",
      "reviewer_name": "Mohsin Ahmed Shaikh",
      "reviewer_id": "174988",
      "aimcr_date": "2026-01-22",
      "project_id": "65633"
    },
    "third_party_software": [
      {
        "name": "Pytorch, Torchvision, Torchaudio",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "Aligns with the proposal objectives. Aligns with the approved research topic Datascience and engineering"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation of PyTorch."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Originally developed by Meta and now governed by Linux Foundation. "
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "https://github.com/pytorch/pytorch/edit/main/docs/source/index.md\nAs of Jan 4th, 2025\n96300 stars\n26400 forks\n12 Github projects\n17000 PRs\n97745 commits\nlast commit 10 hours ago \n\n\n\n"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "KSL will provide NGC container for the requested version of PyTorch. \nnvcr.io/nvidia/pytorch:25.12-py3\n\nNVIDIA Deep Learning Container License\nPermissions:\n- Install and Use\n- Deploy as a Service\n- Create Derived Containers\n- Open Source Development\nRestrictions:\n- No Reverse Engineering\n- No Standalone Distribution: may not distribute or sublicense the CONTAINER as a stand-alone product\n- No Circumventing Security"
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": "nvcr.io/nvidia/pytorch:25.12-py3 contains\n\nCUDA\ncuBLAS\nNVIDIA cuDNN\nNVIDIA NCCL (optimized for NVLink)\nNVIDIA Data Loading Library (DALI)\nTensorRT\nTorch-TensorRT"
          }
        ]
      },
      {
        "name": "MLFlow",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "AI experiment management of logs and metrics. Aligns with the approved research topic Datascience and engineering.\n\nWeights & Biases (wandb) was requested but due to no-internet policy on Shaheen III, MLFlow as an alternative to do local logging and metric collection will be proposed to the applicants."
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Maintained by Databricks (USA) \nThe entity is from non-D5 country"
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "https://pypi.org/project/mlflow/\n\nhttps://github.com/mlflow/mlflow\n\nOwner / Organization: databricks\nRepository: mlflow/mlflow\nStars: 23600\nForks: 5100\nOpen Issues: 1500\nLast Commit Date: 2026-01-08\n"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "Apache License 2.0:\n\nPermissions: \n\nReproduce the Work\n\nPrepare Derivative Works (modifications)\n\nPublicly display the Work\n\nPublicly perform the Work\n\nSublicense the Work\n\nDistribute the Work and Derivative Works in Source or Object form\n\nCommercial use (no charge, royalty-free)\n\nRestrictions:\n\nCannot use trade names, trademarks, service marks, or product names of the Licensor\n\nException: Can use them for reasonable description of the Work's origin or reproducing NOTICE file content"
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": "pip installation: \n\nmlflow-skinny 3.8.1\nmlflow-tracing 3.8.1\nalembic 1.17.2\ncachetools 6.2.4\nclick 8.3.1\ncloudpickle 3.1.2\ncryptography 46.0.3\ndatabricks-sdk 0.77.0\ndocker 7.1.0\nfastapi 0.128.0\nFlask 3.1.2\nflask-cors 6.0.2\nGitPython 3.1.46\ngitdb 4.0.12\ngoogle-auth 2.47.0\ngraphene 3.4.3\ngraphql-core 3.2.7\ngraphql-relay 3.2.0\ngunicorn 23.0.0\nhuey 2.6.0\nimportlib_metadata 8.7.1\nmatplotlib 3.10.8\nnumpy 2.4.0\nopentelemetry-api 1.39.1\nopentelemetry-proto 1.39.1\nopentelemetry-sdk 1.39.1\nopentelemetry-semantic-conventions 0.60b1\npackaging 25.0\npandas 2.3.3\nprotobuf 6.33.2\npyarrow 22.0.0\npydantic 2.12.5\npydantic_core 2.41.5\npython-dateutil 2.9.0.post0\npython-dotenv 1.2.1\nPyYAML 6.0.3\nrequests 2.32.5\ncharset-normalizer 3.4.4\nidna 3.11\nrsa 4.9.1\nscikit-learn 1.8.0\nscipy 1.16.3\nsmmap 5.0.2\nSQLAlchemy 2.0.45\nsqlparse 0.5.5\nstarlette 0.50.0\nanyio 4.12.1\ntyping_extensions 4.15.0\nurllib3 2.6.3\nuvicorn 0.40.0\nannotated-doc 0.0.4\nannotated-types 0.7.0\nblinker 1.9.0\ncertifi 2026.1.4\ncffi 2.0.0\ncontourpy 1.3.3\ncycler 0.12.1\nfonttools 4.61.1\ngreenlet 3.3.0\nh11 0.16.0\nitsdangerous 2.2.0\nJinja2 3.1.6\njoblib 1.5.3\nkiwisolver 1.4.9\nMarkupSafe 3.0.3\npillow 12.1.0\npyasn1 0.6.1\npyasn1_modules 0.4.2\npyparsing 3.3.1\npytz 2025.2\nsix 1.17.0\nthreadpoolctl 3.6.0\ntyping-inspection 0.4.2\ntzdata 2025.3\nWerkzeug 3.1.4\nzipp 3.23.0\nMako 1.3.10\npycparser 2.23"
          }
        ]
      },
      {
        "name": "Deepspeed",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "Distributed training framework from Microsoft. Aligned with approved research topic, datascience & engineering"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No prohibited use indicated. Its a distributed training framework."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "The framework is developed and maintained by Microsoft. The entity is from non-D5 country."
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "https://github.com/microsoft/DeepSpeed\n\nMaintainer / Organization: Microsoft\n\nLast Commit Date: 4 days ago\n\nNumber of Stars: 41K\n\nNumber of Issues (Open/Closed): 1.1K\n\nNumber of PRs (Open/Closed): 102\n\nTotal Commits: 3,004"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "License: Apache License 2.0\n\nPermissions (Apache License 2.0 \u2013 concise version):\n\nUse, reproduce, modify, and create derivative works of the software.\n\nPublicly display, perform, sublicense, and distribute the original work or derivatives (source or binary).\n\nUse patent claims from contributors (if necessarily infringed by their contribution).\n\nSell, offer to sell, import, or transfer the work.\n\nAdd your own copyright notice and apply different license terms to your modifications (if overall redistribution complies).\n\nOffer support, warranty, or indemnity for a fee (on your own responsibility).\n\nUse for any purpose, including commercial.\n\nRestrictions:\n\nProvide recipients with a copy of this license.\n\nInclude prominent notices of changes in modified files.\n\nKeep all original copyright, patent, trademark, and attribution notices in source form.\n\nInclude the NOTICE file (if present) in derivatives, with readable attribution.\n\nDo not use licensor's trademarks, trade names, or product names (except for origin description and NOTICE reproduction).\n\nPatent license ends if you sue any entity for patent infringement related to the work."
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": "deepspeed 0.18.2\npackaging 25.0\npydantic 2.10.6\npydantic_core 2.27.2\neinops 0.8.1\nhjson 3.1.0\nmsgpack 1.1.1\nninja 1.13.0\nnumpy 1.24.4\npsutil 7.2.1\npy-cpuinfo 9.0.0\ntorch 2.2.2\ntqdm 4.67.1\nannotated-types 0.7.0\ntyping_extensions 4.13.2\nfilelock 3.16.1\nfsspec 2025.3.0\nJinja2 3.1.6\nnetworkx 3.1\nsympy 1.13.3\nMarkupSafe 2.1.5\nmpmath 1.3.0"
          }
        ]
      },
      {
        "name": "FlashAttention-2 ",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "It is a memory optimized attention algorithm for transformer architectures. The project will use it during the training of the foundation model. \nAligns with the approved research topic Datascience & engineering"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Owner/Maintainer: Tri Dao (primary developer and maintainer)\nAffiliation: Princeton University (Department of Computer Science) and Together AI\nLinkedIn: https://www.linkedin.com/in/tridao/\n\nThe developer and maintainer of the repository is from non-D5 country."
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "https://github.com/Dao-AI-Lab/flash-attention (correct link: https://github.com/Dao-AILab/flash-attention)\n\nStars: 215000\nFork: 2300\nCommits: 1206\nLatest commit: 11-01-2026"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "BSD 3-Clause License\nPermissions:\n\nCommercial use allowed\n\nModification allowed\n\nDistribution allowed\n\nPrivate use allowed\n\nRestrictions:\n\nMust include copyright notice and license text in distributions\n\nCannot use contributors' names for endorsement without permission\n\nNo trademark rights granted"
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": ""
          }
        ]
      },
      {
        "name": "Scanpy/Squidpy",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "Squidpy is a Python library built on scanpy that provides tools for analyzing spatial molecular data, including spatial transcriptomics, by enabling neighborhood analysis, cell-cell interaction detection, and spatial pattern recognition.\n\nSquidpy is used for data preprocessing and spatial analysis in the proposal.\n\nAligns with the approved research topics Datascience and Engineering and Bioscience."
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Primary maintainers: The scverse consortium, particularly the Theis Lab at Helmholtz Munich\nKey developers:\n\nGiovanni Palla (Helmholtz Munich, Technical University of Munich) - LinkedIn\nHannah Spitzer (Helmholtz Munich)\nFabian Theis (Helmholtz Munich, Technical University of Munich)\n\n\nInstitutional affiliation: Helmholtz Zentrum M\u00fcnchen and scverse community.\n\nAll entities are from non-D5 countries."
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "https://github.com/scverse/squidpy\n\nStars: 546\nForks: 101\nOpen Issues: 91\nLast Commit Date: 2025-12-17"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "Apache License 2.0\n\nPermissions:\n\nCommercial use allowed\n\nModification allowed\n\nDistribution allowed\n\nPatent use granted\n\nPrivate use allowed\n\nRestrictions:\n\nTrademark use not permitted (cannot use NVIDIA or MONAI trademarks without permission)\n\nMust include original copyright notice and license text in distributions\n\nNo liability or warranty provided by contributors"
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": "pip installation (version 1.6.5 was searchable as of 11-01-2026)\n\naiohttp 3.13.3\nanndata 0.11.4\ncycler 0.12.1\ndask-image 2025.11.0\ndocrep 0.3.2\nfsspec 2026.1.0\nmatplotlib 3.10.8\nmatplotlib-scalebar 0.9.0\nnetworkx 3.4.2\nnumba 0.63.1\nnumpy 2.2.6\nomnipath 1.0.12\npandas 2.3.3\npillow 12.1.0\nscanpy 1.11.5\nscikit-image 0.25.2\nscikit-learn 1.7.2\nspatialdata 0.5.0\nstatsmodels 0.14.6\ntifffile 2025.5.10\ntqdm 4.67.1\nvalidators 0.35.0\nxarray 2025.6.1\nzarr 2.18.3\naiohappyeyeballs 2.6.1\naiosignal 1.4.0\narray-api-compat 1.13.0\nasync-timeout 5.0.1\nattrs 25.4.0\nclick 8.3.1\ncloudpickle 3.1.2\ncontourpy 1.3.2\ndask 2024.11.2\nfonttools 4.61.1\nfrozenlist 1.8.0\ngeopandas 1.1.2\nh5py 3.15.1\nImageIO 2.37.2\nimportlib_metadata 8.7.1\ninflect 7.5.0\njoblib 1.5.3\nkiwisolver 1.4.9\nlazy_loader 0.4\nlegacy-api-wrap 1.5\nllvmlite 0.46.0\nmultidict 6.7.0\nmultiscale_spatial_image 2.0.3\nnumcodecs 0.13.1\nome-zarr 0.11.1\npackaging 25.0\npartd 1.4.2\npatsy 1.0.2\nPIMS 0.7\npropcache 0.4.1\npynndescent 0.6.0\npyparsing 3.3.1\npython-dateutil 2.9.0.post0\npytz 2025.2\nPyYAML 6.0.3\nrequests 2.32.5\nscipy 1.15.3\nseaborn 0.13.2\nshapely 2.1.2\nsix 1.17.0\nspatial_image 1.2.3\nthreadpoolctl 3.6.0\ntoolz 1.1.0\ntyping_extensions 4.15.0\ntzdata 2025.3\numap-learn 0.5.9.post2\nurllib3 2.6.3\nwrapt 2.0.1\nxarray-spatial 0.5.2\ndatashader 0.18.2\nyarl 1.22.0\nasciitree 0.3.3\nexceptiongroup 1.3.1\nfasteners 0.20\nnatsort 8.4.0\npooch 1.8.2\npyarrow 22.0.0\nrich 14.2.0\nsession-info2 0.3\nxarray-schema 0.0.3\ncertifi 2026.1.4\ncharset-normalizer 3.4.4\ndask-expr 1.1.19\nidna 3.11\nmarkdown-it-py 4.0.0\nmore-itertools 10.8.0\nplatformdirs 4.5.1\nPygments 2.19.2\npyogrio 0.12.1\npyproj 3.7.1\nslicerator 1.1.0\ntypeguard 4.4.4\nxarray-dataclass 3.0.0\nzipp 3.23.0\ncolorcet 3.1.0\nlocket 1.0.0\nmultipledispatch 1.0.0\nparam 2.3.1\npyct 0.6.0\nmdurl 0.1.2\ns3fs 2026.1.0\naiobotocore 3.1.0\naioitertools 0.13.0\nbotocore 1.42.19\njmespath 1.0.1\nsetuptools 80.9.0"
          }
        ]
      },
      {
        "name": "MONAI",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "MONAI (Medical Open Network for AI) is an opensource PyTorch-based framework developed by NVIDIA for deep learning in healthcare imaging, providing domain-optimized tools for medical image analysis including preprocessing, training, and deployment.\n\n MONAI is used for H&E whole-slide image (WSI) processing in the proposal, specifically for:\n\nWSI I/O (input/output) operations\nImage tiling of histological whole-slide images\nData augmentations and transformations for H&E tissue images\nSupporting the vision transformer that processes tiled H&E images\n\nAligns with approved research topics Health and wellness, Bioscience, and Datascience & engineering"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation."
          },
          {
            "name": "D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Owner: NVIDIA Corporation (with open-source community contributions)\nPrimary maintainers: NVIDIA Healthcare AI team and Project MONAI Consortium\n\nKey leadership:\n\nWenqi Li (NVIDIA, MONAI Technical Lead)\n\nPrerna Dogra (NVIDIA, Product Manager)\n\nTigmanshu Bhatnagar (NVIDIA)\n\n\nConsortium members: King's College London, NVIDIA, various academic medical centers\n\nAll entities are from non-D5 countries."
          },
          {
            "name": "Source / Provenance",
            "score": 1,
            "notes": "nvcr.io/nvidia/clara/monai-toolkit:3.0\nContainer image maintained by NVIDIA in NGC catalog\n\nhttps://github.com/Project-MONAI/MONAI\n\nStars: 7700\nForks: 1400\nCommits: 3301\nLast commit: 07-01-2026"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "Container image license: NVIDIA AI Product Agreement.\n\nGithub license: Apache 2.0\nPermissions:\n\nCommercial use allowed\nModification allowed\nDistribution allowed\nPatent use granted\nPrivate use allowed\n\nRestrictions:\n\nMust include copy of license\nMust include NOTICE file if provided\nMust state significant changes made\nCannot use NVIDIA trademarks without permission\nNo liability or warranty provided by contributors"
          },
          {
            "name": "Bundled Tools / Dependencies",
            "score": 1,
            "notes": "Singularity\nnvcr.io/nvidia/clara/monai-toolkit:3.0"
          }
        ]
      }
    ],
    "source_code": [],
    "datasets_user_files": [
      {
        "name": "Serial multi-plane sections for 3D reconstruction",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "Serial ST + H&E sections anchored to Allen CCF. \nThe project will use the data to train/validate virtual slicing and z-continuity\nNot a separate dataset (property of MERFISH dataset)\n\nAligns with approved research topic, Bioscience"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "D5+M affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "Allen Institute owns it. \n\nEntity from non-D5 country."
          },
          {
            "name": "Prompts / Fine-tuning Scripts",
            "score": 1,
            "notes": " no user files provided."
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "low risk. skipping inspection."
          },
          {
            "name": "Provenance",
            "score": 1,
            "notes": "https://www.nature.com/articles/s41586-023-06812-z \n\nThe atlas and underlying scRNA-seq/MERFISH datasets were generated by the author consortium and released with the Allen Brain Cell Atlas / Allen Institute as the primary public platform for the mouse whole-brain cell-type atlas."
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "CC BY 4.0: permits use, sharing, adaptation, distribution, and reproduction (with attribution, link to license, and change indication)."
          }
        ]
      },
      {
        "name": "Whole-brain  scRNA-seq  (AIBS,  BICCN)",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "The NeMO collection \u201cA high-resolution transcriptomic and spatial atlas of cell types in the whole mouse brain\u201d contains whole-brain scRNA-seq (~7 million cells) plus spatially resolved transcriptomics via MERFISH (~4.3 million cells) for adult mouse brain cell-type atlas building. "
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "D5+M affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "The collection credits Zizhen Yao (Allen Institute) as contact/contributor, and the archive platform itself is built and maintained by the Institute for Genome Sciences, University of Maryland School of Medicine; a LinkedIn profile is readily findable for Hongkui Zeng (Allen Institute for Brain Science) who is listed in the dataset citation authorship. https://nemoarchive.org/abou \n\nNon-D5"
          },
          {
            "name": "Prompts / Fine-tuning Scripts",
            "score": 1,
            "notes": "No scripts provided"
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "Skipped"
          },
          {
            "name": "Provenance",
            "score": 1,
            "notes": "The underlying atlas dataset is attributed to Allen Institute-led authors (e.g., Hongkui Zeng, Zizhen Yao, and collaborators; 2023) and is distributed/hosted via NeMO Archive, which is maintained by University of Maryland School of Medicine\u2019s Institute for Genome Sciences\n\nhttps://assets.nemoarchive.org/dat-qg7n1b0\n\nDownload through wget: wget -r https://download.brainimagelibrary.org/ab/cd/abcdef0123456789/example_dataset_01/ "
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "The collection is marked CC BY 4.0 on NeMO (attribution required).\n\nCommercial use is allowed under CC BY 4.0 (with attribution + link to license + change indication).\n\nAdaptation/remix is allowed under CC BY 4.0 (same attribution requirements).\n\nNo additional legal/technical restrictions may be applied beyond the license terms"
          }
        ]
      },
      {
        "name": "Whole-brain  spatial  transcriptomics  (AIBS  MERFISH,  BICCN) ",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "This Brain Image Library dataset (\u201cMouse whole-brain transcriptomic cell type atlas \u2013 MERSCOPE v1\u201d) contains whole-brain spatial transcriptomics imaging across adult mouse (P56) brain sections, profiling ~500 genes on 10 \u00b5m sections acquired every 200 \u00b5m (and notes re-segmentation with Cellpose).\n\nIt supports the proposal\u2019s objectives to curate mouse-brain cohorts with spatial transcriptomics across serial sections, align RNA\u2194ST and enable 3D reconstruction / z-continuity / virtual slicing by providing whole-brain ST data that can be registered to an atlas. \n\nAligns with approved research topic Bioscience. "
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "D5+M affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "The dataset is attributed to the Allen Institute for Brain Science (ProjectLeader: Hongkui Zeng, with other Allen Institute contributors listed), while it is hosted/distributed by the Brain Image Library; LinkedIn for Hongkui Zeng is publicly findable.\n\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC11633743\n\nUnited States (USA) \u2014 the dataset was created by the Allen Institute for Brain Science, which is a US-based research institute, and it is hosted/distributed via the Brain Image Library (BIL), also US-based. \nNon-D5\n"
          },
          {
            "name": "Prompts / Fine-tuning Scripts",
            "score": 1,
            "notes": "No scripts provided"
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "low risk. Skipping inspection."
          },
          {
            "name": "Provenance",
            "score": 1,
            "notes": "It was created/produced by the Allen Institute team (as cited on the DOI landing page) and then published/archived in the Brain Image Library under DOI 10.35077/g.610 (BIL serving as the distribution platform)."
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "License/rights are not explicitly stated on the DOI landing page text shown (only citation, abstract, contributors, and download link are visible), so the exact permission/restriction terms cannot be confirmed from this page alone.\n\nThe page does indicate the dataset is available for download via BIL (linked download directory), but no formal license string is displayed there."
          }
        ]
      }
    ],
    "models": [
      {
        "name": "scGPT",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "scGPT is a generative pre-trained transformer \u201cfoundation model\u201d for single-cell (and related) omics that learns cell/gene representations from large-scale single-cell profiles and can be adapted to multiple downstream analysis tasks.\nUsed to initialize the RNA encoder for the Brain-3D-FM model they are building.\nThe URL specifies multiple models available for download. We assumed the usage of the model named brain - according to inspecting the proposal and the project scope.\n\nAligns with the approved research topic, Bioscience and Datascience and Engineering."
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "Source / Provenance & D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "\nThe model is maintained by the Bo Wang Lab (Bo Wang\u2014University of Toronto / Vector Institute / UHN affiliations listed in the scGPT paper metadata; LinkedIn profiles found for Bo Wang and Haotian Cui). https://www.linkedin.com/in/bo-wang-a6065240 Canada - Non-D5 Country"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "License: MIT License.\n\nPermits commercial use, modification, distribution, and private use (with inclusion of the license/copyright notice in copies).\n\nProvided \u201cas is\u201d with no warranty / liability"
          },
          {
            "name": "Training Data Documentation",
            "score": 1,
            "notes": "Pretrained on 13.2 million brain cells. \u224810\u2078\u201310\u2079 gene token"
          },
          {
            "name": "Customisation / Fine-tuning",
            "score": 1,
            "notes": "scGPT includes downstream fine-tuning for cell-type representation learning on public scRNA-seq datasets. The documentation/examples describe fine-tuning/use for tasks including scRNA-seq integration (batch correction/integration), cell-type annotation, and other downstream workflows (e.g., GRN-related and embedding/zero-shot utilities listed in project materials)."
          },
          {
            "name": "FLOPS Calculation",
            "score": 1,
            "notes": "Number of parameters were not accurately indicated by the PI for this model, even in the additional information. \n\nHowever, downloading the checkponit and loading it reveals that there are 51.33 million parameters in the state_dict which encapsulates the weights, biases, and activations. \n\nConsidering 13.2 million samples converts to 10^9 tokens according to PI provided additional information.\n\nEstimated FLOPS = 6 x 51.3 x 10^6 x 10^9 = 307.8 x 10^15 \n\nThis is orders of magnitude less than the threshold of 10^27. \n"
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "no risk in LC2.7 check. skipping inspection."
          }
        ],
        "is_proprietary": false
      },
      {
        "name": "UNI",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "UNI is a self-supervised vision transformer foundation encoder for histopathology that turns H&E whole-slide tissue patches into general-purpose embeddings for many computational pathology tasks.\nUsed to initialize the histology encoder for the Brain-3D-FM multi-modal system being developed.\n\nAligns with approved research topics, Bioscience and Datascience & engineering"
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "Source / Provenance & D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "https://huggingface.co/MahmoodLab/UNI \nDownloads in Dec 2025: 36,339\n\nhttps://github.com/mahmoodlab/UNI \nStars: 655\nCommits: 34\nLast update: 10 months ago\nOwned by:  Mahmood Lab @ Harvard/MGB  - AI for Pathology Image Analysis Lab @ HMS / BWH\nNon-D5 Country"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "License: CC BY-NC-ND 4.0.\n\nNon-commercial only: use is limited to non-commercial (e.g., academic research) use.\n\nNo derivatives: redistribution of modified/adapted versions is restricted under \u201cNoDerivatives.\u201d"
          },
          {
            "name": "Training Data Documentation",
            "score": 1,
            "notes": "UNI was pretrained on Mass-100K dataset consisting of according to Source: https://pmc.ncbi.nlm.nih.gov/articles/PMC11403354/pdf/nihms-2015612.pdf \n\n75,832,905 images at 256 \u00d7 256 pixels (at \u00d720 magnification)\n24,297,995 images at 512 \u00d7 512 pixels (at \u00d720 magnification)\nTotal: 100,130,900 images\n\nFrom the paper, it is noted that the images were fed to model (ViT) as 16x16 patch:\nThis means each 16\u00d716 pixel patch becomes one token.\nToken Calculation:\nFor 256\u00d7256 images:\n\nTokens per image = (256/16)\u00b2 = 16\u00b2 = 256 tokens\n\nTotal tokens = 75,832,905 \u00d7 256 = 19,413,223,680 tokens\n\nFor 512\u00d7512 images:\nTokens per image = (512/16)\u00b2 = 32\u00b2 = 1,024 tokens\n\nTotal tokens = 24,297,995 \u00d7 1,024 = 24,881,146,880 tokens\n\nTotal Training Tokens:\nTotal = 19,413,223,680 + 24,881,146,880 = 44,294,370,560 tokens \n\nApproximately 44.29B"
          },
          {
            "name": "Customisation / Fine-tuning",
            "score": 1,
            "notes": "The authors report UNI as a general-purpose encoder evaluated across 34 representative computational pathology tasks (i.e., used as a transferable feature backbone for diverse clinical prediction tasks)."
          },
          {
            "name": "FLOPS Calculation",
            "score": 1,
            "notes": "UNI is commonly described as a ViT-L/16\u2013class encoder with ~307M parameters.\nTokens = 44.29 x 10^9\nEstimated FLOPs= 6 x 307 x 10^6 x 44.29 x 10^9 = 81.58 x 10^18\n\nThis is orders of magnitude less than the threshold 10^27.\n\n"
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "no risk in LC2.7 check, skipping inspection."
          }
        ],
        "is_proprietary": false
      },
      {
        "name": "UNI2-h",
        "checks": [
          {
            "name": "Project & Usage Alignment",
            "score": 1,
            "notes": "UNI2-h (UNI 2) is a self-supervised ViT-H/14 pathology foundation encoder that extracts general-purpose embeddings from histopathology image regions/tiles for downstream computational pathology tasks. Used to initialize the histology encoder for the Brain-3D-FM multi-modal system being developed.\n\nAligns with approved research topic Bioscience, and Datascience and engineering."
          },
          {
            "name": "Prohibited Use Screening (LC 2.7)",
            "score": 1,
            "notes": "No mention of sensitive terms in the documentation classified in Prohibited Use Screening in accordance with LC 2.7."
          },
          {
            "name": "Source / Provenance & D5+M Affiliation Screening (LC 2.5)",
            "score": 1,
            "notes": "HF: https://huggingface.co/MahmoodLab/UNI2-h\n\nDownloads in Dec 2025: 36,339\n\nhttps://github.com/mahmoodlab/UNI \n\nStars: 655 \nCommits: 34 \nLast update: 10 months ago \nOwned by: Mahmood Lab @ Harvard/MGB - AI for Pathology Image Analysis Lab @ HMS / BWH Non-D5 Country"
          },
          {
            "name": "License / Permissions",
            "score": 1,
            "notes": "License: CC BY-NC-ND 4.0.\n\nNon-commercial only (academic/research use with attribution); commercial use/monetization requires prior approval.\n\nNo redistribution / reproduction of the model copy per access terms on the model page.\n\nNo derivatives (per \u201cND\u201d in CC BY-NC-ND)"
          },
          {
            "name": "Training Data Documentation",
            "score": 1,
            "notes": "From the article: https://www.nature.com/articles/s41591-024-02857-3 \n\nTraining images: \"Over 200 million image tiles sampled from over 350k diverse H&E and IHC slides\"\nModel architecture: article describes the patch size used is 14x14 pixles.\nInput size: 224x224 pixels\n\nToken Calculation:\n\nTokens per image:\nEach image: 224x224 pixels\nPatch size: 14x14 pixels\nTokens per image = (224/14)^2 = 16^2 = 256 tokens\n\nTotal tokens:\n\nImages: ~200 million \nTotal = 200 x 10^6 x 256 = 51.2 billion tokens"
          },
          {
            "name": "Customisation / Fine-tuning",
            "score": 1,
            "notes": "UNI2-h was released as foundation model and was not fine tuned for any downstream tasks itself."
          },
          {
            "name": "FLOPS Calculation",
            "score": 1,
            "notes": "According to the article as well as the additional information provided by the PI:\n\nNumber of parameters in UNI2-h: 681M\nNumber of training tokens: 51.2 B\n\nEstimated FLOPS= 6 x 681 x 10^6 x 51.2 x 10^9 = 2.092 x 10^20\n\nLess than the threshold of 10^27. "
          },
          {
            "name": "Sample Inspection",
            "score": 1,
            "notes": "no risk in LC2.7 check. Skipping inspection."
          }
        ],
        "is_proprietary": false
      }
    ],
    "observations": "Additional information by the PI has indicated three datasets and 3 models. All the datasets are comming from Allen Institute for Brain Science, USA.\n\nThe models are small and vision transformers. The number of tokens, though big, still hasn't enabled any of the requested models to accumulate anywhere near the 10^27 threshold. ",
    "recommendation": "Positive checks passed.\nNegative checks passed. \n10^27 check passed.\n\nThe final recommendation is to proceed the grand challenge. "
  }
}