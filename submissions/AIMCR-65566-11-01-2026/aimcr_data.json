{
  "metadata": {
    "proposal_title": " Integrated multi-scale modeling, protein foundation models, and autonomous AI agents",
    "principal_investigator": "Sameer Hamdan",
    "proposal_date": "2025-10-23",
    "reviewer_name": "Mohsin Ahmed Shaikh",
    "reviewer_id": "174988",
    "aimcr_date": "2026-01-11",
    "project_id": "65566"
  },
  "third_party_software": [
    {
      "name": "pytorch",
      "checks": [
        {
          "name": "Project & Usage Alignment",
          "score": 1,
          "notes": "Aligns with the proposal objectives. Aligns with the approved research topic Datascience and engineering."
        },
        {
          "name": "Prohibited Use Screening (LC 2.7)",
          "score": 1,
          "notes": "No mention of sensitive terms in the documentation of PyTorch.\nFrom a non D5 country."
        },
        {
          "name": "Restricted Entities Screening (LC 2.5)",
          "score": 1,
          "notes": "Originally developed by Meta and now governed by Linux Foundation."
        },
        {
          "name": "Source / Provenance",
          "score": 1,
          "notes": "https://github.com/pytorch/pytorch/edit/main/docs/source/index.md As of Jan 4th, 2025 96300 stars 26400 forks 12 Github projects 17000 PRs 97745 commits last commit 10 hours ago"
        },
        {
          "name": "License / Permissions",
          "score": 1,
          "notes": "NVIDIA End user license. Permits the proposed work.\n\nNVIDIA Deep Learning Container License Permissions:\n\nInstall and Use\nDeploy as a Service\nCreate Derived Containers\nOpen Source Development Restrictions:\nNo Reverse Engineering\nNo Standalone Distribution: may not distribute or sublicense the CONTAINER as a stand-alone product\nNo Circumventing Security"
        },
        {
          "name": "Bundled Tools / Dependencies",
          "score": 1,
          "notes": "nvcr.io/nvidia/pytorch:25.12-py3 contains\nCUDA cuBLAS NVIDIA cuDNN NVIDIA NCCL (optimized for NVLink) NVIDIA Data Loading Library (DALI) TensorRT Torch-TensorRT"
        }
      ]
    },
    {
      "name": "vLLM",
      "checks": [
        {
          "name": "Project & Usage Alignment",
          "score": 1,
          "notes": "Inference engine for LLMs. \nAligns with the proposal objectives. \nAligns with the approved research topic Datascience and engineering."
        },
        {
          "name": "Prohibited Use Screening (LC 2.7)",
          "score": 1,
          "notes": "No mention of sensitive terms in the documentation of vLLM."
        },
        {
          "name": "Restricted Entities Screening (LC 2.5)",
          "score": 1,
          "notes": " Owner: Sky Computing Lab at UC Berkeley (https://sky.cs.berkeley.edu/)\nFrom a non D5 country."
        },
        {
          "name": "Source / Provenance",
          "score": 1,
          "notes": "https://github.com/vllm-project/vllm\n\nStars: 66997\n\nForks: 12428\n\nOpen Issues: 3099\n\nLast Commit Date: 2026-01-07T07:36:13Z"
        },
        {
          "name": "License / Permissions",
          "score": 1,
          "notes": " Apache-2.0 license (open-source):\n\nUse, modify, distribute: You can use the code/data freely in academic, personal, or commercial projects.\n\nPatent grant: Contributors grant you a license to any patents covering their contributions.\n\nNotice required: Must include the original copyright, license notice, and any changes you made.\n\nNo warranty: Comes \u201cas-is,\u201d so you\u2019re responsible for any issues.\n\nNo obligation to share modifications:  you don\u2019t have to release your derivative works under the same license."
        },
        {
          "name": "Bundled Tools / Dependencies",
          "score": 1,
          "notes": "anthropic 0.71.0\n\ncompressed-tensors 0.12.2\n\ndepyf 0.20.0\n\ndiskcache 5.6.3\n\nflashinfer-python 0.5.3\n\nlark 1.2.2\n\nlm-format-enforcer 0.11.3\n\nnumba 0.61.2\n\noutlines_core 0.2.11\n\ntorch 2.9.0\n\nnvidia-cublas-cu12 12.8.4.1\n\nnvidia-cuda-cupti-cu12 12.8.90\n\nnvidia-cuda-nvrtc-cu12 12.8.93\n\nnvidia-cuda-runtime-cu12 12.8.90\n\nnvidia-cudnn-cu12 9.10.2.21\n\nnvidia-cufft-cu12 11.3.3.83\n\nnvidia-cufile-cu12 1.13.1.3\n\nnvidia-curand-cu12 10.3.9.90\n\nnvidia-cusolver-cu12 11.7.3.90\n\nnvidia-cusparse-cu12 12.5.8.93\n\nnvidia-cusparselt-cu12 0.7.1\n\nnvidia-nccl-cu12 2.27.5\n\nnvidia-nvjitlink-cu12 12.8.93\n\nnvidia-nvshmem-cu12 3.3.20\n\nnvidia-nvtx-cu12 12.8.90\n\ntorchaudio 2.9.0\n\ntorchvision 0.24.0\n\ntriton 3.5.0\n\nxgrammar 0.1.27\n\nanyio 4.12.1\n\napache-tvm-ffi 0.1.7\n\ndistro 1.9.0\n\ndocstring_parser 0.17.0\n\nhttpx 0.28.1\n\nhttpcore 1.0.9\n\njiter 0.12.0\n\nllguidance 1.3.0\n\nllvmlite 0.44.0\n\nmodel-hosting-container-standards 0.1.13\n\nnumpy 2.2.6\n\npydantic 2.12.5\n\npydantic_core 2.41.5\n\ntransformers 4.57.3\n\nhuggingface-hub 0.36.0\n\nhf-xet 1.2.0\n\ntokenizers 0.22.2\n\ntyping_extensions 4.15.0\n\nannotated-types 0.7.0\n\nexceptiongroup 1.3.1\n\nfastapi 0.128.0\n\nstarlette 0.50.0\n\nannotated-doc 0.0.4\n\nemail-validator 2.3.0\n\ndnspython 2.8.0\n\nfastapi-cli 0.0.20\n\nfastapi-cloud-cli 0.9.0\n\nfastar 0.8.0\n\nfilelock 3.20.3\n\nfsspec 2026.1.0\n\ngguf 0.17.1\n\nh11 0.16.0\n\nidna 3.11\n\ninteregular 0.3.3\n\nJinja2 3.1.6\n\nMarkupSafe 3.0.3\n\nmistral_common 1.8.8\n\njsonschema 4.26.0\n\nattrs 25.4.0\n\njsonschema-specifications 2025.9.1\n\nnetworkx 3.4.2\n\nnvidia-cudnn-frontend 1.17.0\n\nnvidia-cutlass-dsl 4.3.5\n\ncuda-python 13.1.1\n\ncuda-bindings 13.1.1\n\ncuda-pathfinder 1.3.3\n\nopenai 2.15.0\n\nopenai-harmony 0.0.8\n\nopencv-python-headless 4.12.0.88\n\npackaging 25.0\n\npillow 12.1.0\n\nprometheus_client 0.23.1\n\nprometheus-fastapi-instrumentator 7.1.0\n\npydantic-extra-types 2.11.0\n\npycountry 24.6.1\n\npydantic-settings 2.12.0\n\npython-dotenv 1.2.1\n\npython-multipart 0.0.21\n\nPyYAML 6.0.3\n\npyzmq 27.1.0\n\nray 2.53.0\n\nmsgpack 1.1.2\n\nclick 8.3.1\n\nprotobuf 6.33.3\n\nreferencing 0.37.0\n\nregex 2025.11.3\n\nrequests 2.32.5\n\ncharset-normalizer 3.4.4\n\nurllib3 2.6.3\n\ncertifi 2026.1.4\n\nrich-toolkit 0.17.1\n\nrich 14.2.0\n\nPygments 2.19.2\n\nmarkdown-it-py 4.0.0\n\nmdurl 0.1.2\n\nrignore 0.7.6\n\nrpds-py 0.30.0\n\nsafetensors 0.7.0\n\nsentry-sdk 2.49.0\n\nsupervisor 4.3.0\n\nsympy 1.14.0\n\nmpmath 1.3.0\n\ntiktoken 0.12.0\n\ntomli 2.4.0\n\ntqdm 4.67.1\n\ntyper 0.21.1\n\nshellingham 1.5.4\n\ntyping-inspection 0.4.2\n\nuvicorn 0.40.0\n\nhttptools 0.7.1\n\nuvloop 0.22.1\n\nwatchfiles 1.1.1\n\nwebsockets 16.0\n\naiohttp 3.13.3\n\nasync-timeout 5.0.1\n\nmultidict 6.7.0\n\nyarl 1.22.0\n\naiohappyeyeballs 2.6.1\n\naiosignal 1.4.0\n\nfrozenlist 1.8.0\n\npropcache 0.4.1\n\nastor 0.8.1\n\nblake3 1.0.8\n\ncachetools 6.2.4\n\ncbor2 5.8.0\n\ncloudpickle 3.1.2\n\ncupy-cuda12x 13.6.0\n\nfastrlock 0.8.3\n\ndill 0.4.0\n\neinops 0.8.1\n\nijson 3.4.0.post0\n\njmespath 1.0.1\n\nloguru 0.7.3\n\nmcp 1.25.0\n\nhttpx-sse 0.4.3\n\nPyJWT 2.10.1\n\ncryptography 46.0.3\n\ncffi 2.0.0\n\nsse-starlette 3.1.2\n\nmsgspec 0.20.0\n\nninja 1.13.0\n\nnvidia-ml-py 13.590.44\n\npartial-json-parser 0.2.1.1.post7\n\npsutil 7.2.1\n\npy-cpuinfo 9.0.0\n\npybase64 1.4.3\n\npycparser 2.23\n\npython-json-logger 4.0.0\n\nscipy 1.15.3\n\nsentencepiece 0.2.1\n\nsetproctitle 1.3.7\n\nsetuptools 80.9.0\n\nsniffio 1.3.1\n\ntabulate 0.9.0\n"
        }
      ]
    }
  ],
  "source_code": [],
  "datasets_user_files": [],
  "models": [
    {
      "name": "DeepSeek-LLM",
      "checks": [
        {
          "name": "Project & Usage Alignment",
          "score": 1,
          "notes": "Deepseek is general Large Language Model, Aligns with approved research topics Material Sciences and Datascience & engineering"
        },
        {
          "name": "Prohibited Use Screening (LC 2.7)",
          "score": 1,
          "notes": "No notes of prohibited use in documentation."
        },
        {
          "name": "Source / Provenance & Restricted Entities (LC 2.5)",
          "score": 1,
          "notes": "Owner:  (Hangzhou DeepSeek Artificial Intelligence Co., Ltd.) https://huggingface.co/deepseek-ai/collections\nFounder: Liang Wenfeng (https://www.linkedin.com/in/wenfeng-liang-837841128/)\nThe entity is from China, one of D5 countries.\n\n"
        },
        {
          "name": "License / Permissions",
          "score": 1,
          "notes": "MIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:"
        },
        {
          "name": "Training Data Documentation",
          "score": 1,
          "notes": "Large-scale deduplicated web corpus predominantly English + Chinese\n\nToken count: 2T\n\nData provenance: Publicly described as Common Crawl\u2013derived"
        },
        {
          "name": "Customisation / Fine-tuning",
          "score": 1,
          "notes": "no fine tuning scripts provided"
        },
        {
          "name": "FLOPS Calculation",
          "score": 1,
          "notes": "Not mentioned"
        },
        {
          "name": "Sample Inspection",
          "score": 1,
          "notes": "low risk. Skipping sample inspection."
        }
      ]
    },
    {
      "name": "Gemma",
      "checks": [
        {
          "name": "Project & Usage Alignment",
          "score": 1,
          "notes": "Gemma is a family of lightweight, state-of-the-art multimodal models from Google, capable of handling text, image, video, and audio input, and generating text outputs. \n\nAligns with approved research topics Material Sciences and Datascience & engineering."
        },
        {
          "name": "Prohibited Use Screening (LC 2.7)",
          "score": 1,
          "notes": "No mention of prohibited Use in Documentation."
        },
        {
          "name": "Source / Provenance & Restricted Entities (LC 2.5)",
          "score": 1,
          "notes": "Owner: Google (https://huggingface.co/google/collections)\nFrom a non D5 country.\n"
        },
        {
          "name": "License / Permissions",
          "score": 1,
          "notes": "Gemma Terms of Use (Google)\n\nPermissions:\n\nUse the Gemma models and related services (\u201cGemma Services\u201d) for your projects.\n\nReproduce Gemma.\n\nModify Gemma and create Model Derivatives (including fine\u2011tuning and adaptations).\n\nDistribute Gemma or Model Derivatives to third parties if you comply with the distribution conditions.\n\nUse, perform, or display Gemma or Model Derivatives according to the Terms.\n\nRestrictions:\n\nProhibited Uses: You must not use Gemma or derivatives for uses prohibited by the Gemma Prohibited Use Policy (e.g., generating content that violates rights, infringes IP, etc.).\n\nMust comply with applicable laws and regulations.\n\nYou may not imply endorsement by Google or use Google trademarks.\n\nGoogle can restrict usage if it reasonably believes the Terms are violated."
        },
        {
          "name": "Training Data Documentation",
          "score": 1,
          "notes": "Not mentioned"
        },
        {
          "name": "Customisation / Fine-tuning",
          "score": 1,
          "notes": "no fine tuning scripts provided"
        },
        {
          "name": "FLOPS Calculation",
          "score": 1,
          "notes": "Not Mentioned"
        },
        {
          "name": "Sample Inspection",
          "score": 1,
          "notes": "low risk. Skipping sample inspection."
        }
      ]
    }
  ],
  "observations": "Amber, Gromacs, \n\nFor the dataset (colab-fold), there is no single ColabFold dataset URL. \n\nThe core databases are available through their respective public sources: UniProt, MGnify, BFD/Mgnify, and the Protein Data Bank (PDB).\nThese are hosted on Ibex at the moment and are in frequent use. Risk is mitigated by the fact that they are published by ",
  "recommendation": "Contact the applicant about specifying which datasets are required to be moved to Shaheen III GPUP.\nRecommended for grand challenge. ",
  "_submission_history": [
    {
      "timestamp": "2026-01-12T08:26:43.407546",
      "action": "resubmission"
    }
  ]
}